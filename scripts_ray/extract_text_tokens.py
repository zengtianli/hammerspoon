#!/usr/bin/env python3
"""
è®¡ç®—æ–‡ä»¶çš„ token æ•°é‡
å®‰è£…: pip install tiktoken
"""

import tiktoken
import sys
import os

def count_tokens(text, model="gpt-3.5-turbo"):
    """è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡"""
    encodings = {
        "gpt-4": "cl100k_base",
        "gpt-3.5-turbo": "cl100k_base",
        "text-davinci-003": "p50k_base",
        "text-davinci-002": "p50k_base",
        "davinci": "r50k_base",
    }
    
    encoding_name = encodings.get(model, "cl100k_base")
    encoding = tiktoken.get_encoding(encoding_name)
    
    num_tokens = len(encoding.encode(text))
    return num_tokens

def analyze_file(filename):
    """åˆ†ææ–‡ä»¶çš„ token ä¿¡æ¯"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è®¡ç®—å„ç§æ¨¡å‹çš„ token æ•°
        models = ["gpt-3.5-turbo", "gpt-4", "text-davinci-003"]
        
        print(f"\nğŸ“„ æ–‡ä»¶: {filename}")
        print(f"ğŸ“ å¤§å°: {os.path.getsize(filename) / 1024:.2f} KB")
        print(f"ğŸ“ å­—ç¬¦æ•°: {len(content):,}")
        print(f"ğŸ“– å­—æ•°(ä¼°ç®—): {len(content.split()):,}")
        print("\nğŸ”¢ Token æ•°é‡:")
        
        for model in models:
            tokens = count_tokens(content, model)
            print(f"  - {model}: {tokens:,} tokens")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python count_tokens.py <æ–‡ä»¶å>")
        sys.exit(1)
    
    analyze_file(sys.argv[1])

